## TRAINING 1:
### Dataset:
finalDataset.csv campionato con 9000 istanze per label (13).

### Risultati:
**TRAIN** \
PRECISION: 0.8500041948068291 \
RECALL: 0.8500041948068291 \
F1_SCORE: 0.8500041948068291

**TEST** \
PRECISION: 0.7629614093959731\
RECALL: 0.7629614093959731\
F1_SCORE: 0.762961409395973\


## TRAINING 2:
### Dataset:
finalDatasetNoMerge.csv (cioè il dataset orginale con NESSUNA MODIFICA, solo le label accorpate) campionato con 5000 istanze per label (14).

### Risultati:
**TRAIN** \
PRECISION: 0.8539608105844917 \
RECALL: 0.8539608105844917 \
F1_SCORE: 0.8539608105844917

**TEST** \
PRECISION: 0.7487020599564562\
RECALL: 0.7487020599564562\
F1_SCORE: 0.7487020599564562\


## TRAINING 3:
### Dataset:
finalDatasetNoMerge.csv (cioè il dataset orginale con NESSUNA MODIFICA, solo le label accorpate) NON campionato

### Risultati:
**TRAIN** \
PRECISION: 0.8520414919443832 \
RECALL: 0.8520414919443832 \
F1_SCORE: 0.8520414919443832

**TEST** \
PRECISION: 0.7783113810515908\
RECALL: 0.7783113810515908\
F1_SCORE: 0.7783113810515908\


## TRAINING 4:
### Dataset:
finalDatasetNoMerge.csv (cioè il dataset orginale con NESSUNA MODIFICA, solo le label accorpate) campionato con 15000

### Risultati:
**TRAIN** \
PRECISION: 0.8466417426632666 \
RECALL: 0.8466417426632666 \
F1_SCORE: 0.8466417426632666

**TEST** \
PRECISION: 0.7568396939966288\
RECALL: 0.7568396939966288\
F1_SCORE: 0.7568396939966288\


## TRAINING 5:
### Dataset:
finalDatasetOriginalIntegrated.csv (cioè il dataset orginale con l'integrazione del testo) NON campionato.

### Risultati:
**TRAIN** \
PRECISION: 0.8578446871123866 \
RECALL: 0.8578446871123866 \
F1_SCORE: 0.8578446871123866

**TEST** \
PRECISION: 0.7918801478695117\
RECALL: 0.7918801478695117\
F1_SCORE: 0.7918801478695117\

## TRAINING 6:
### Dataset:
finalDatasetOriginalIntegrated.csv (cioè il dataset orginale con l'integrazione del testo) con oversampling a 12000 istanze e campionato con createRandomDataset()

### Risultati:
**TRAIN** \
PRECISION: 0.9056392743432777 \
RECALL: 0.9056392743432777 \
F1_SCORE: 0.9056392743432777

**TEST** \
PRECISION: 0.8378716931611441\
RECALL: 0.8378716931611441\
F1_SCORE: 0.8378716931611441\



## TRAINING 7:
### Dataset:
finalDatasetOriginalIntegrated.csv (cioè il dataset orginale con l'integrazione del testo) con oversampling a 17000 istanze e campionato con createRandomDataset()

### Risultati:
**TRAIN** \
PRECISION: 0.92874291447994 \
RECALL: 0.92874291447994 \
F1_SCORE: 0.92874291447994

**TEST** \
PRECISION: 0.8728487675723381\
RECALL: 0.8728487675723381\
F1_SCORE: 0.8728487675723381\


## TRAINING 8:
### Dataset:
finalDatasetOriginalIntegrated.csv (cioè il dataset orginale con l'integrazione del testo) con oversampling a 17000 istanze e campionato con createRandomDataset()

### Risultati:
**TRAIN** \
PRECISION: 0.9375229840511901 \
RECALL: 0.9375229840511901 \
F1_SCORE: 0.9375229840511901

**TEST** \
PRECISION: 0.8888411143044649\
RECALL: 0.8888411143044649\
F1_SCORE: 0.8888411143044649\


### Naive Bayes     TRAIN

### --------------PRECISION--------------

- 'ARTS & CULTURE': 0.9778678070372872,
- 'BUSINESS': 0.8988170523026561,
- 'EDUCATION': 0.9668460710441334,
- 'ENTERTAINMENT': 0.9082990180551156,
- 'FOOD & DRINK': 0.9578304276560871,
- 'HOME & LIVING': 0.9719516660563896,
- 'PARENTING': 0.8531241547200433,
- 'POLITICS': 0.8870808678500987,
- 'SCIENCE & MATHEMATICS': 0.9873150105708245,
- 'SPORTS': 0.9701034017683201,
- 'STYLE & BEAUTY': 0.9277886203272782,
- 'TECH': 0.9725046210720887,
- 'TRAVEL': 0.9176554681915654

--------------RECALL--------------

- 'ARTS & CULTURE': 0.9557820635037032
- 'BUSINESS': 0.8910606284112701,
- 'EDUCATION': 0.9910261125413755,
- 'ENTERTAINMENT': 0.8476204552172628,
- 'FOOD & DRINK': 0.942176621473067,
- 'HOME & LIVING': 0.9750936742340753,
- 'PARENTING': 0.936043923430776,
- 'POLITICS': 0.9192641798671436,
- 'SCIENCE & MATHEMATICS': 0.9936899258933157,
- 'SPORTS': 0.9490543908517812,
- 'STYLE & BEAUTY': 0.914268806864413,
- 'TECH': 0.928729037952339,
- 'TRAVEL': 0.9431384072876874

--------------F1_SCORE--------------

- 'ARTS & CULTURE': 0.9666988059037306,
- 'BUSINESS': 0.894922034149413,
- 'EDUCATION': 0.9787867780602978,
- 'ENTERTAINMENT': 0.8769113149847095,
- 'FOOD & DRINK': 0.949939040159604,
- 'HOME & LIVING': 0.9735201349666252,
- 'PARENTING': 0.8926625627962924,
- 'POLITICS': 0.9028858218318695,
- 'SCIENCE & MATHEMATICS': 0.9904922109266437,
- 'SPORTS': 0.959463465243812,
- 'STYLE & BEAUTY': 0.9209790991393763,
- 'TECH': 0.9501128668171558,
- 'TRAVEL': 0.9302224476487211}
Naive Bayes     TEST

--------------PRECISION--------------

{- 'ARTS & CULTURE': 0.9454893210073319
- 'BUSINESS': 0.8032036613272311
- 'EDUCATION': 0.9480079118395027
- 'ENTERTAINMENT': 0.8327655620935274
- 'FOOD & DRINK': 0.92841512972804
- 'HOME & LIVING': 0.9441290708096803
- 'PARENTING': 0.7677136596055515
- 'POLITICS': 0.8176733780760627
- 'SCIENCE & MATHEMATICS': 0.9766892888757746
- 'SPORTS': 0.9573594440934934
- 'STYLE & BEAUTY': 0.8742268041237113
- 'TECH': 0.9531199482702878
- 'TRAVEL': 0.8518202502844141

--------------RECALL--------------

- 'ARTS & CULTURE': 0.8819506393101397
- 'BUSINESS': 0.8297872340425532
- 'EDUCATION': 0.9853157121879589
- 'ENTERTAINMENT': 0.7753748558246828
- 'FOOD & DRINK': 0.8852459016393442
- 'HOME & LIVING': 0.9324284449690174
- 'PARENTING': 0.8952299829642248
- 'POLITICS': 0.8857921841866101
- 'SCIENCE & MATHEMATICS': 0.9819044793829724
- 'SPORTS': 0.9026206075044669
- 'STYLE & BEAUTY': 0.8526285550129273
- 'TECH': 0.8660399529964747
- 'TRAVEL': 0.8840023612750886

--------------F1_SCORE--------------

- 'ARTS & CULTURE': 0.9126153846153846
- 'BUSINESS': 0.8162790697674418
- 'EDUCATION': 0.9663018433179723
- 'ENTERTAINMENT': 0.8030461400627147
- 'FOOD & DRINK': 0.9063167531278608
- 'HOME & LIVING': 0.9382422802850356
- 'PARENTING': 0.8265827762485253
- 'POLITICS': 0.8503708012214628
- 'SCIENCE & MATHEMATICS': 0.9792899408284024
- 'SPORTS': 0.9291845493562232
- 'STYLE & BEAUTY': 0.8632926119837114
- 'TECH': 0.9074957672772048
- 'TRAVEL': 0.8676129779837775

